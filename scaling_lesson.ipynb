{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4ad091-312f-4ba6-babd-fdb7e2981378",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydataset\n",
    "import seaborn as sns\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c069360-074a-445e-a3f9-9fd44970471a",
   "metadata": {},
   "source": [
    "# Scaling\n",
    "\n",
    "Scaling changes the range of features in our dataset.\n",
    "\n",
    "0. tldr\n",
    "\n",
    "    - Use a min-max scaler before you do modeling.\n",
    "    - Generally prefer unscaled data, except in modeling.\n",
    "    - Learn parameters for scaling from the training split.\n",
    "\n",
    "1. Scaling - when, where, what, why, and how\n",
    "\n",
    "    - why\n",
    "        - some model types can be thrown off by different feature scales\n",
    "        - improves most model's implementation\n",
    "        - visualize the combination of 2 variables with different scales\n",
    "        - a better interpretation of the data (e.g. log scaling)\n",
    "        - combining features\n",
    "    - when\n",
    "        - data prep / exploration\n",
    "        - pipeline: prep\n",
    "        - lifecycle: prep/exploration\n",
    "        - when one of the conditions above is met. Otherwise, it's better to work with the original units\n",
    "    - where\n",
    "        - the training dataset\n",
    "        - usually just the independent variables\n",
    "        - indep vars are scaled independently, i.e. the scaling of one feature doesn't affect the scaling of another\n",
    "        - scale whatever goes into the model\n",
    "    - how\n",
    "        - `sklearn.preprocessing` -- requires 2d array\n",
    "        - make the thing, fit the thing, use the thing\n",
    "        - `.fit` to learn parameters, `.transform` to apply the scaling\n",
    "        - seperate scaled dataframes and/or columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75a373a-110c-4087-be47-65bf8306ebda",
   "metadata": {},
   "source": [
    "## Why Scale? A Motivating Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1617187d-84ae-496a-a30d-49de7302c961",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('https://gist.githubusercontent.com/zgulde/66989745314d2c68ab62fae13743f094/raw/71635c6281b5e2a36e3eb4578cab277eb09743ec/train.csv')\n",
    "test = pd.read_csv('https://gist.githubusercontent.com/zgulde/66989745314d2c68ab62fae13743f094/raw/71635c6281b5e2a36e3eb4578cab277eb09743ec/test.csv')\n",
    "print('train shape: %d x %d' % train.shape)\n",
    "print('test shape: %d x %d' % test.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c652848-88d1-419e-9701-f9816ecd1098",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train[['pints', 'n_sprinkles']], test[['pints', 'n_sprinkles']]\n",
    "y_train, y_test = train.flavor, test.flavor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f552c6-6881-4970-8fb5-e5a717729dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=3)\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c09071-2fd7-443b-8606-16da40eb21bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1665e86-513a-4ef3-947c-614c1d2a13cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train_scaled, y_train)\n",
    "model.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ff12c7-265b-4190-9384-97fc59db0de5",
   "metadata": {},
   "source": [
    "What's going on?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b89acc8-659f-4d1e-a286-3df74c2b4561",
   "metadata": {},
   "source": [
    "### Another Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0e8fae-c0c5-43f4-bea7-09b7fab0084d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pydataset.data('sat.act')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f3b3af-6d22-4842-86c9-08ddeb412368",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['gender', 'ACT', 'SATV', 'SATQ']].groupby('gender').mean().plot.bar(figsize=(11, 6), ec='black', width=.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085a4902-9dad-4e56-891d-8e071f6b0b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "\n",
    "cols = ['education', 'age', 'ACT', 'SATQ', 'SATV']\n",
    "scaler = StandardScaler()\n",
    "df[cols] = scaler.fit_transform(df[cols])\n",
    "df[['gender', 'ACT', 'SATV', 'SATQ']].groupby('gender').mean().plot.bar(figsize=(11, 6), ec='black', width=.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a898f15b-5a5b-4616-88f8-57a6dac887b0",
   "metadata": {},
   "source": [
    "## Linear Scaling\n",
    "\n",
    "- Units are changed, but the distance between points is preserved.\n",
    "\n",
    "- MinMax: everything between 0 and 1\n",
    "\n",
    "    $$ x' = \\frac{x - \\text{max}(x)}{\\text{max}(x) - \\text{min}(x)} $$\n",
    "\n",
    "- Standard: a zscore, standard deviations from the mean, **center** + **scale**\n",
    "\n",
    "    $$ x' = \\frac{x - \\bar{x}}{s_x} $$\n",
    "\n",
    "    - **centering**: subtracting the mean\n",
    "    - **scaling**: dividing by the standard deviation\n",
    "\n",
    "- Robust: robust to and preserves outliers\n",
    "\n",
    "    $$ x' = \\frac{x - \\text{med}(x)}{\\text{IQR}_x} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568bcc64-51ad-4189-968e-f638b36976be",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling_example = pd.DataFrame()\n",
    "scaling_example['x1'] = np.arange(1, 11)\n",
    "scaling_example['x2'] = [-100, -1, 0, 1, 2, 3, 4, 5, 100, 1000]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaling_example[['x1_minmax', 'x2_minmax']] = scaler.fit_transform(scaling_example[['x1', 'x2']])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaling_example[['x1_standard', 'x2_standard']] = scaler.fit_transform(scaling_example[['x1', 'x2']])\n",
    "\n",
    "scaler = RobustScaler()\n",
    "scaling_example[['x1_robust', 'x2_robust']] = scaler.fit_transform(scaling_example[['x1', 'x2']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99483969-09d9-4da8-ab66-09ac7b5e39fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling_example[sorted(scaling_example)] # sort columns alphabetically"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8010d53-b92a-4f41-ae48-7b77a015b592",
   "metadata": {},
   "source": [
    "## Non-linear Scaling\n",
    "\n",
    "- The distance between points is **not** preserved, but order is\n",
    "- Not as common as linear scalers\n",
    "- In sklearn: power transformation: box-cox, yeo-johnson; quantile transformation\n",
    "- Log\n",
    "\n",
    "    $$ x' = \\log_b{x} $$\n",
    "\n",
    "    $$ b^{x'} = x $$\n",
    "\n",
    "    Sometimes you can just set the x/y scale w/ matplotlib instead of\n",
    "    actually transforming the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ab5024-b502-428b-96fb-50b417847ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "n = 100\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['x1'] = np.random.randn(n)\n",
    "df['x2'] = 10 ** (df.x1 + np.random.randn(n) * .5)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 6))\n",
    "ax.scatter(df.x1, df.x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909eff1a-86f1-44e9-9727-c722d686152a",
   "metadata": {},
   "source": [
    "## Futher Reading\n",
    "\n",
    "[Visual Demos](https://stats-demos.zach.wiki/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
